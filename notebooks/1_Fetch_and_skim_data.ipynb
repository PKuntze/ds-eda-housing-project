{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL in Python - Connecting to and retrieving data from PostgreSQL\n",
    "\n",
    "Previously, you have learned how to connect to a SQL database by using a SQL client such as DBeaver. Apart from connecting to databases, DBeaver also allows you to run SQL queries against the database, create new tables and populate them with data as well as retrieving the data.\n",
    "\n",
    "Python also allows executing SQL queries and getting the result into a Python object, for example a Pandas data frame. Instead of exporting a .csv file from DBeaver you can directly get the data you need into Python and continue your work. In addition we can reduce the steps by connecting to the database from Python directly, eliminating the need for a separate SQL client.\n",
    "\n",
    "After you have the data in Python in the required shape you can export the data into a .csv file. This file is for your own reference, please avoid sending .csv files around - database is the point of reference when it comes to data. \n",
    "\n",
    "Having a copy of a .csv file (or another format) can speed up your analysis work. Imagine that the query takes 25 minutes to run. If you made some mistakes in your Python code you might need to go back to the original dataset. Instead of having to rerun the SQL query and having to wait you can read in the .csv file you have previously saved on your hard disk into Python and continue with your analysis work. \n",
    "\n",
    "**In this notebook you will see 2 ways to connect to SQL-Databases and export the data to a CSV file**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a connection to a PostgreSQL database with Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 python packages that are the \"go-to\" when it comes to connecting to SQL-Databases: `psycopg2` and `sqlalchemy` "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting via psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to create a connection to our PostgreSQL database we need the following information:\n",
    "\n",
    "- host = the address of the machine the database is hosted on\n",
    "- port = the virtual gate number through which communication will be allowed\n",
    "- database = the name of the database\n",
    "- user = the name of the user\n",
    "- password = the password of the user\n",
    "\n",
    "Because we don't want that the database information is published on github we put it into a `.env` file which is added into the `.gitignore`. \n",
    "In these kind of files you can store information that is not supposed to be published.\n",
    "With the `dotenv` package you can read the `.env` files and get the variables.\n",
    "(We will share the file with you on Slack!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DATABASE = os.getenv('DATABASE')\n",
    "USER_DB = os.getenv('USER_DB')\n",
    "PASSWORD = os.getenv('PASSWORD')\n",
    "HOST = os.getenv('HOST')\n",
    "PORT = os.getenv('PORT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function from the psycopg2 package to create a connection is called `connect()`.\n",
    "`connect()` expects the parameters listed above as input in order to connect to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection object conn\n",
    "conn = psycopg2.connect(\n",
    "    database=DATABASE,\n",
    "    user=USER_DB,\n",
    "    password=PASSWORD,\n",
    "    host=HOST,\n",
    "    port=PORT\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving data from the database with psycopg2\n",
    "\n",
    "Before we can use our connection to get data, we have to create a cursor. A cursor allows Python code to execute PostgreSQL commmands in a database session.\n",
    "A cursor has to be created with the `cursor()` method of our connection object conn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run SQL-Queries with `cur.execute('QUERY')` and then run `cur.fetchall()` to get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2014, 10, 13), 221900.0, 7129300520, 1),\n",
       " (datetime.date(2014, 12, 9), 538000.0, 6414100192, 2),\n",
       " (datetime.date(2015, 2, 25), 180000.0, 5631500400, 3),\n",
       " (datetime.date(2014, 12, 9), 604000.0, 2487200875, 4),\n",
       " (datetime.date(2015, 2, 18), 510000.0, 1954400510, 5),\n",
       " (datetime.date(2014, 5, 12), 1230000.0, 7237550310, 6),\n",
       " (datetime.date(2014, 6, 27), 257500.0, 1321400060, 7),\n",
       " (datetime.date(2015, 1, 15), 291850.0, 2008000270, 8),\n",
       " (datetime.date(2015, 4, 15), 229500.0, 2414600126, 9),\n",
       " (datetime.date(2015, 3, 12), 323000.0, 3793500160, 10)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT * FROM eda.king_county_house_sales LIMIT 10')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `conn.close()` you can close the connection again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want to work with the data. The easiest way is to import the data into pandas dataframes. We can use `pd.read_sql_query` or `pd.read_sql_table` or for convenience `pd.read_sql`.\n",
    "\n",
    "This function is a convenience wrapper around read_sql_table and read_sql_query (for backward compatibility). It will delegate to the specific function depending on the provided input. A SQL query will be routed to read_sql_query , while a database table name will be routed to read_sql_table . Note that the delegated function might have more specific notes about their functionality not listed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open connection again because we closed it\n",
    "conn = psycopg2.connect(\n",
    "    database=DATABASE,\n",
    "    user=USER_DB,\n",
    "    password=PASSWORD,\n",
    "    host=HOST,\n",
    "    port=PORT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xv/2jhhwq6s0yx_pd196qcw40980000gn/T/ipykernel_39594/1176423828.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_psycopg = pd.read_sql(query_string, conn)\n"
     ]
    }
   ],
   "source": [
    "# import the data into a pandas dataframe\n",
    "query_string = \"SELECT * FROM eda.king_county_house_sales LIMIT 10\"\n",
    "df_psycopg = pd.read_sql(query_string, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   date      10 non-null     object \n",
      " 1   price     10 non-null     float64\n",
      " 2   house_id  10 non-null     int64  \n",
      " 3   id        10 non-null     int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 452.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_psycopg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the data to a csv-file\n",
    "df_psycopg.to_csv('../data/eda.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting and retrieving data via SQLAlchemy\n",
    "\n",
    "`sqlalchemy` works similarly. Here you have to create an engine with the database sting (a link that includes every information we entered in the conn object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "#read the database string from the .env\n",
    "load_dotenv()\n",
    "\n",
    "DB_STRING = os.getenv('DB_STRING')\n",
    "\n",
    "db = create_engine(DB_STRING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can import that engine with a query into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"SELECT d.*, s.id as sales_id, s.date, s.price FROM eda.king_county_house_sales s FULL OUTER JOIN eda.king_county_house_details d on s.house_id=d.id\"\n",
    "df_outer = pd.read_sql(query_string, db)\n",
    "df_outer.rename(columns={'id': 'house_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   house_id       21597 non-null  int64  \n",
      " 1   bedrooms       21597 non-null  float64\n",
      " 2   bathrooms      21597 non-null  float64\n",
      " 3   sqft_living    21597 non-null  float64\n",
      " 4   sqft_lot       21597 non-null  float64\n",
      " 5   floors         21597 non-null  float64\n",
      " 6   waterfront     19206 non-null  float64\n",
      " 7   view           21534 non-null  float64\n",
      " 8   condition      21597 non-null  int64  \n",
      " 9   grade          21597 non-null  int64  \n",
      " 10  sqft_above     21597 non-null  float64\n",
      " 11  sqft_basement  21145 non-null  float64\n",
      " 12  yr_built       21597 non-null  int64  \n",
      " 13  yr_renovated   17749 non-null  float64\n",
      " 14  zipcode        21597 non-null  int64  \n",
      " 15  lat            21597 non-null  float64\n",
      " 16  long           21597 non-null  float64\n",
      " 17  sqft_living15  21597 non-null  float64\n",
      " 18  sqft_lot15     21597 non-null  float64\n",
      " 19  sales_id       21597 non-null  int64  \n",
      " 20  date           21597 non-null  object \n",
      " 21  price          21597 non-null  float64\n",
      "dtypes: float64(15), int64(6), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_outer.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         house_id  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
      "21592   263000018       3.0       2.50       1530.0    1131.0     3.0   \n",
      "21593  6600060120       4.0       2.50       2310.0    5813.0     2.0   \n",
      "21594  1523300141       2.0       0.75       1020.0    1350.0     2.0   \n",
      "21595   291310100       3.0       2.50       1600.0    2388.0     2.0   \n",
      "21596  1523300157       2.0       0.75       1020.0    1076.0     2.0   \n",
      "\n",
      "       waterfront  view  condition  grade  ...  yr_built  yr_renovated  \\\n",
      "21592         0.0   0.0          3      8  ...      2009           0.0   \n",
      "21593         0.0   0.0          3      8  ...      2014           0.0   \n",
      "21594         0.0   0.0          3      7  ...      2009           0.0   \n",
      "21595         NaN   0.0          3      8  ...      2004           0.0   \n",
      "21596         0.0   0.0          3      7  ...      2008           0.0   \n",
      "\n",
      "       zipcode      lat     long  sqft_living15  sqft_lot15  sales_id  \\\n",
      "21592    98103  47.6993 -122.346         1530.0      1509.0     21593   \n",
      "21593    98146  47.5107 -122.362         1830.0      7200.0     21594   \n",
      "21594    98144  47.5944 -122.299         1020.0      2007.0     21595   \n",
      "21595    98027  47.5345 -122.069         1410.0      1287.0     21596   \n",
      "21596    98144  47.5941 -122.299         1020.0      1357.0     21597   \n",
      "\n",
      "             date     price  \n",
      "21592  2014-05-21  360000.0  \n",
      "21593  2015-02-23  400000.0  \n",
      "21594  2014-06-23  402101.0  \n",
      "21595  2015-01-16  400000.0  \n",
      "21596  2014-10-15  325000.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_outer.tail())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we don't want to run the queries over and over again we can export the data into a .csv file in order to use it in other notebooks as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the data to a csv-file\n",
    "df_outer.to_csv('../data/eda.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
